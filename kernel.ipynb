{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Lambda\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense, Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils.np_utils import to_categorical\nfrom keras.datasets import mnist\nfrom keras.layers.advanced_activations import PReLU\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import Callback",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c3405fc445871e00d2d65e77a6383d6b19467ef9"
      },
      "cell_type": "code",
      "source": "data=pd.read_csv(\"../input/train.csv\")\ny=data.ix[:,0].values\nX=data.ix[:,1:data.shape[1]].values\nprint(X.shape,y.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3eb84487db5e05bd1c2746a88bb85154324b33e4"
      },
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\nX_train=X_train.reshape(X_train.shape[0],28,28,1).astype('float32')\nX_test=X_test.reshape(X_test.shape[0],28,28,1).astype('float32')\nprint(X_train.shape)\nprint(X_test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d3d952acadc2771a98f13d092507f0c44f345ef0"
      },
      "cell_type": "code",
      "source": "X_train_ = X_train.reshape(X_train.shape[0], 28, 28)\n\nfor i in range(0, 3):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train_[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i]);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0ff594f88a673dd4a0b46ebcffa601e222d8677"
      },
      "cell_type": "code",
      "source": "y_train=to_categorical(y_train)\ny_test=to_categorical(y_test)\nnum_classes=y_test.shape[1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c0224eb6b70061a8afd8af7f52c4618e89c7570e"
      },
      "cell_type": "code",
      "source": "gen=image.ImageDataGenerator()\nbatches=gen.flow(X_train,y_train,batch_size=64)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "774e65ffef5121f8de775ac200bfb571e749505c"
      },
      "cell_type": "code",
      "source": "mean=np.mean(X_train)\nstd=np.std(X_train)\n\ndef standardize(x):\n    return (x-mean)/std",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c8f113bdee61a6e4ee15a48c2f8e987de8f7cff0"
      },
      "cell_type": "code",
      "source": "#写一个LossHistory类，保存loss和acc\nclass LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = {'batch':[], 'epoch':[]}\n        self.accuracy = {'batch':[], 'epoch':[]}\n        self.val_loss = {'batch':[], 'epoch':[]}\n        self.val_acc = {'batch':[], 'epoch':[]}\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses['batch'].append(logs.get('loss'))\n        self.accuracy['batch'].append(logs.get('acc'))\n        self.val_loss['batch'].append(logs.get('val_loss'))\n        self.val_acc['batch'].append(logs.get('val_acc'))\n\n    def on_epoch_end(self, batch, logs={}):\n        self.losses['epoch'].append(logs.get('loss'))\n        self.accuracy['epoch'].append(logs.get('acc'))\n        self.val_loss['epoch'].append(logs.get('val_loss'))\n        self.val_acc['epoch'].append(logs.get('val_acc'))\n\n    def loss_plot(self, loss_type):\n        iters = range(len(self.losses[loss_type]))\n        plt.figure()\n        # loss\n        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n        # val_loss\n        plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n        plt.grid(True)\n        plt.xlabel(loss_type)\n        plt.ylabel('loss')\n        plt.legend(loc=\"upper right\")\n        plt.show()\n    def acc_plot(self, loss_type):\n        iters = range(len(self.losses[loss_type]))\n        plt.figure()\n        # acc\n        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n        # val_acc\n        plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n        plt.grid(True)\n        plt.xlabel(loss_type)\n        plt.ylabel('acc')\n        plt.legend(loc=\"upper right\")\n        plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28009d5ec5d9ca6cbd73b95be029c3665840511e"
      },
      "cell_type": "code",
      "source": "#创建一个实例history\nhistory = LossHistory()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16907be54f6e9cf94ac5b841e23aeaec0e5dbb18"
      },
      "cell_type": "code",
      "source": "# from keras.callbacks import ReduceLROnPlateau\n# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=2, mode='auto',min_lr=0)\nimport keras.backend as K\nfrom keras.callbacks import LearningRateScheduler",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9bb1fb7e5d93c0252734584f604d77f5b776daf"
      },
      "cell_type": "code",
      "source": "def model():\n    model=Sequential()\n    model.add(Lambda(standardize,input_shape=(28,28,1)))\n    model.add(Conv2D(64,(3,3),activation=\"relu\"))\n    model.add(Conv2D(64,(3,3),activation=\"relu\"))\n    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128,(3,3),activation=\"relu\"))\n    model.add(Conv2D(128,(3,3),activation=\"relu\"))\n    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Conv2D(256,(3,3),activation=\"relu\"))\n    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.5))\n    \n    model.add(Flatten())\n    model.add(BatchNormalization())\n    model.add(Dense(512,activation=\"relu\"))\n    model.add(Dense(10,activation=\"softmax\"))\n    \n    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n    def scheduler(epoch):\n    # 每隔100个epoch，学习率减小为原来的1/10\n        if epoch % 20 == 0 and epoch != 0:\n            lr = K.get_value(model.optimizer.lr)\n            K.set_value(model.optimizer.lr, lr * 0.1)\n            print(\"lr changed to {}\".format(lr * 0.1))\n        return K.get_value(model.optimizer.lr)\n    reduce_lr = LearningRateScheduler(scheduler)\n    model.fit_generator(generator=batches,steps_per_epoch=batches.n/batches.batch_size,epochs=60,\n                        validation_data=(X_test, y_test),callbacks=[history,reduce_lr])\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d4fd4fffd96128fd2a92cb6926a91a368b14339"
      },
      "cell_type": "code",
      "source": "model=model()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b9f76eb917a72b761d87c3bc094d0ca36b55228"
      },
      "cell_type": "code",
      "source": "score=model.evaluate(X_test,y_test,verbose=0)\nprint(\"CNN Error:%.2f%%\" %(100-score[1]*100))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "215e5cb6089e19f675fdc046876798b053c14b9b"
      },
      "cell_type": "code",
      "source": "X_test=pd.read_csv('../input/test.csv')\nX_test=X_test.values.reshape(X_test.shape[0],28,28,1)\npreds=model.predict_classes(X_test,verbose=1)\nmodel.save('digit_recognizer.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf6c36afc10c0ec32efecf7d05243b2b5f868e0c"
      },
      "cell_type": "code",
      "source": "def write_preds(preds,fname):\n    pd.DataFrame({\"ImageId\":list(range(1,len(preds)+1)),\"Label\":preds}).to_csv(fname,index=False,header=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f2ba1b2394bb32155095bfd1556542f1045ddd69"
      },
      "cell_type": "code",
      "source": "write_preds(preds,\"result.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c900c0304be0085d66b6b81f2c452ccade3eb1b"
      },
      "cell_type": "code",
      "source": "#绘制acc-loss曲线\nhistory.loss_plot('epoch')\nhistory.acc_plot('epoch')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}